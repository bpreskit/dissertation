
 In this section we will use spectral graph theoretic techniques to obtain a bound on the error associated with recovering phase information using our method.  % namely $\min\limits_{\theta \in [0, 2\pi]} ||\tx - \ee^{\ii \theta} \tx_0||_2$.  
In particular, we will adapt the proof of Theorem 6.3 from \cite{alexeev2014phase} to develop a bound for $\min_{\theta\in[0,2\pi]} \Vert \tx_0 - \mathbbm{e}^{\mathbbm{i}\theta}\tx \Vert_2$.  This approach involves considering both $\tX$ from Algorithm~\ref{alg:phaseRetrieval1} and $\widetilde{\X}_0$ from \eqref{eq:X_0} in the context of spectral graph theory, so we begin by defining essential terms.  The idea is to consider a graph whose vertices correspond to the entries of $\tx_0$ from \eqref{eq:X_0}, and whose edges carry the relative phase data.\footnote{The interested reader is also referred to Appendix~\ref{sec:AltPerturbBounds} where more standard perturbation theoretic techniques are utilized in order to obtain a  weaker bound on the error associated with recovering phase information via the proposed approach.}
\\

We begin with an undirected graph $G = (V, E)$ with vertex set $V = \{1, 2, \dots, d\}$ and weight mapping $w: V \times V \to \R^+$, where $w_{ij} = w_{ji}$ and $w_{ij} = 0$ iff $\{i, j\} \notin E$.  The \emph{degree} of a vertex $i$ is \[\deg(i) := \sum_{j ~{\rm s.t.}~ (i, j) \in E} w_{ij},\] and we define the \emph{degree matrix} and \emph{weighted adjacency matrix} of $G$ by \[D := \diag(\deg(i)) \ \text{and} \ W_{ij} := w_{ij}, \label{eq:degandweight}\] respectively.  The \emph{volume} of $G$ is \[\vol(G) := \sum_{i \in V} \deg(i).\]  Finally, the \emph{Laplacian} of $G$ is the $d \times d$ real symmetric matrix \begin{equation} L := I - D^{-1/2} W D^{-1/2} = D^{-1/2}(D - W)D^{-1/2}, \label{eq:graph_laplacian_normd}\end{equation}
where $I \in \{ 0,1\}^{d \times d}$ is the identity matrix.  

When $G$ is connected, Lemma 1.7 of \cite{chungspectral} shows that the nullspace of $(D - W)$ is $\Span(\mathbbm{1})$, and the nullspace of $L$ is $\Span(D^{1/2}\mathbbm{1})$.  Observing that $D - W$ is diagonally semi-dominant, it follows from Gershgorin's disc theorem that $(D - W)$ and $L$ are both positive semidefinite.  Alternatively, one may also note that 
\begin{equation*} \v^*(D - W)\v = \sum_{i \in V} \left(v_i^2\deg(i) - \sum_{j \in V} v_i v_j w_{ij}\right) = \frac{1}{2} \sum_{i, j \in V} w_{ij} (v_i - v_j)^2 \geq 0 \end{equation*}
holds for all $\v \in \mathbbm{R}^d$.  Thus, we may order the eigenvalues of $L$ in increasing order so that $0 = \lambda'_1 < \lambda'_2 \le \cdots \le \lambda'_n$.  
We then define the \emph{spectral gap} of $G$ to be $\tau = \lambda'_2$.

Herein, though we will state the main theorem of this section more generally, we will mainly be interested in the case where the graph $G=(V,E)$ is the simple unweighted graph whose adjacency matrix is $U = T_{\delta}(\mathbbm{1} \mathbbm{1}^*)$ as in \eqref{equ:NormedUmatSPG}.  In this case we will have $W = U - I_d$ and $D = (2 \delta - 2)I_d$.  We also immediately obtain the following corollary of Lemmas~\ref{lem:spectrum} and~\ref{lem:EigGap}.
\begin{corollary}\label{cor:Gspectrum}
Let $G$ be the simple unweighted graph whose adjacency matrix is $U$ from \eqref{equ:NormedUmatSPG}.  Let $L$ be the Laplacian of $G$.  Then, there exists a bijection $\sigma:[d] \rightarrow [d]$ such that
$$\lambda'_{\sigma(j)} = \frac{2 \delta - 1}{2 \delta - 2} - \frac{1 + 2 \sum_{k = 1}^{\delta - 1}\cos\left(\bigfrac{2\pi (j-1) k}{d}\right)}{2 \delta - 2}$$
for $j = 1, \dots, d$.  In particular, if $d \geq 4 \delta$ and $\delta \geq 3$ then \[\tau = \lambda'_2 > \dfrac{\pi^2}{6} \dfrac{\delta^2}{d^2}.\]
\end{corollary}
Using this graph $G$ as a scaffold we can now represent our computed relative phase matrix $\tX$ from Algorithm~\ref{alg:phaseRetrieval1} by noting that for some (Hermitian) perturbations $\eta_{ij}$ 
we will have 
\begin{equation}
\tX_{ij} = \bigfrac{(x_0)_i(x_0)_j^* + \eta_{ij}}{|(x_0)_i(x_0)_j^* + \eta_{ij}|} \cdot w_{ij} = \bigfrac{(x_0)_i(x_0)_j^* + \eta_{ij}}{|(x_0)_i(x_0)_j^* + \eta_{ij}|} \cdot \chi_{E(i, j)}.
\label{equ:DeftildeXviaGcomp}
\end{equation}
%Recall that in this instance and throughout this discussion, we consider $\frac{(\cdot)}{|\cdot|}$ to denote the function $\sgn : \C \to \mathcal{S}^1$ defined by \[\sgn(z) = \left\{\begin{array}{r@{,\ }l} z / |z| & z \neq 0 \\ 1 & z = 0\end{array}\right.\]  For ${\bf z} \in \Cn$, we consider $\sgn$ to operate entrywise. 
 Using this same notation we may also represent our original phase matrix $\widetilde{\X}_0$ %from 
%\eqref{equ:MatrixofPhases} 
via $G$ by noting that
\begin{equation}
(\widetilde{\X}_0)_{ij} = \bigfrac{(x_0)_i(x_0)_j^*}{|(x_0)_i(x_0)_j^*|} \cdot w_{ij} = \sgn \left( (x_0)_i(x_0)_j^* \right) \cdot \chi_{E(i, j)}.
\label{equ:DeftildeXviaGpure}
\end{equation}

%%We also consider data in the form of a mapping $\rho : V \times V \to \mathcal{S}^1 \cup \{0\}$.  This is used to represent our computed relative phase matrix $\tX$ from Algorithm~
%%\ref{alg:phaseRetrieval}; that is, we assume for some (Hermitian) perturbations $\eta_{ij}$ that we have \[\rho_{ij} = \bigfrac{(x_0)_i^*(x_0)_j + \eta_{ij}}{|(x_0)_i^*(x_0)_j + \eta_{ij}|} \cdot \chi_{E(i, j)}.\]  In this 
%%instance and throughout this discussion, we consider $\frac{(\cdot)}{|\cdot|}$ to denote the function $\sgn : \C \to \mathcal{S}^1$ defined by \[\sgn(z) = \left\{\begin{array}{r@{,\ }l} z / |z| & z \neq 0 \\ 1 & z = 
%%0\end{array}\right.\]  For ${\bf z} \in \Cn$, we consider $\sgn$ to operate pointwise.

We may now define the \emph{connection Laplacian} of the graph $G$ associated with the Hermitian and entrywise normalized data given by $\tX$ to be the matrix 
\begin{equation}
L_1 = I - D^{-1/2} (\tX \circ W) D^{-1/2},
\label{equ:ConnectLaplace}
\end{equation}
where $\circ$ denotes entrywise (Hadamard) multiplication.
%%We then define the \emph{connection Laplacian} of the graph $G$ conjoined with the relative phase data $\rho$ to be the matrix \[L_1 = I - D^{-1/2} A_1 D^{-1/2},\] where $(A_1)_{ij} = \rho_{ij}$.  We 
%%also define $A_0$ by \[(A_0)_{ij} = \bigfrac{x_i^*x_j}{|x_i^*x_j|} \cdot \chi_E(i, j).\]
Following \cite{Cheeger}, given $\tX$ and a vector $\y \in \mathbbm{C}^d$, we  define the \emph{frustration of} $\y$ \emph{with respect to} $\tX$ by \begin{equation} \eta_{\tX}(\y) := \bigfrac{1}{2}\bigfrac{\sum_{(i, j) \in E} w_{ij}|y_i - \tX_{ij} y_j |^2}{\sum_{i \in V} \deg(i) |y_i|^2} = \bigfrac{\y^* (D - (\tX \circ W)) \y}{\y^* D \y}. \label{eq:frustration} \end{equation}
We may consider $\eta_{\tX}(\y)$ to measure how well $\y$ (viewed as a map from $V$ to $\mathbbm{C}$) conforms to the computed relative phase differences $\tX$ across the graph $G$. %We will need the following simple lemmas.

%\begin{lemma}
%  For any real numbers $a, b \in \R$, we have $\frac{1}{2} a^2 - b^2 \le (a - b)^2$.
%  \label{lem:SimpGTB1}
%\end{lemma}
%
%\begin{proof}  Rearranging, we have $0 \le \frac{1}{2} a^2 + 2b^2 - 2 a b = \frac{1}{2}(a - 2b)^2$. \end{proof}

%% \begin{lemma} For any $a, b \in \C$ with $|a| = 1$, we have $|a - \sgn(b)| \le 2 |a - b|$. 
%% \label{lem:SimpGTB2}
%% \end{lemma}

%\begin{proof}  Well, consider that $|\sgn(b) - b| = |1 - |b| | = | |a| - |b| | \le |a - b|$, so $|a - \sgn(b)| \le |a - b| + |b - \sgn(b)| \le 2 |a - b|$. \end{proof}

In addition, we adapt a result from \cite{Cheeger}:

\begin{lemma}[Cheeger inequality for the connection Laplacian] \label{lem:CheegerInequality}
Suppose that $G = (V=[d], E)$ is a connected graph with degree matrix $D \in [0,\infty)^{d \times d}$, weighted adjacency matrix $W \in [0,\infty)^{d \times d}$, and spectral gap $\tau > 0$, and that $\tX \in \mathbbm{C}^{d \times d}$ is Hermitian and entrywise normalized.  Let ${\bf u} \in \mathbbm{C}^d$ be an eigenvector of $L_1$ from \eqref{equ:ConnectLaplace} corresponding to its smallest eigenvalue.  Then, ${\bf w} = \sgn({\bf u}) = \sgn \left( D^{-1/2}{\bf u} \right)$ satisfies \[\eta_{\tX}({\bf w}) \le \bigfrac{44}{\tau} \cdot \min_{\y \in \mathbbm{C}^d} \eta_{\tX}( \sgn(\y) ).\]
\end{lemma}

\begin{proof}[Proof of \cref{lem:CheegerInequality}]
 %%Consider that finding the smallest eigenvalue of $L_1$ relaxes the problem $\min_{\omega : V \to \S^1} \eta(\omega)$, as 
 One can see that 
\begin{align*}
\inf_{\v \in \C^d \setminus \{ \bf 0 \}} \bigfrac{\v^* L_1 \v}{\v^* \v} &= \inf_{\y \in \C^d \setminus \{ \bf 0 \}} \bigfrac{(D^{1/2}\y)^* L_1 (D^{1/2} \y)}{(D^{1/2}\y)^*(D^{1/2} \y)} = \inf_{\y \in \C^d \setminus \{ \bf 0 \} } \bigfrac{\y^*(D - (\tX \circ W))\y}{\y^* D \y } \\
&= \inf_{y \in \C^d \setminus \{ \bf 0 \}} \eta_{\tX}(\y) \le \min_{\y \in \mathbbm{C}^d} \eta_{\tX}( \sgn(\y) ).  
\end{align*}
From here, Lemma 3.6 in \cite{Cheeger} gives \[\eta_{\tX}({\bf w}) \le \bigfrac{44}{\tau} \eta_{\tX}\left( D^{-1/2}{\bf u} \right) = \bigfrac{44}{\tau} \cdot \inf_{\v \in \C^d \setminus \{ \bf 0 \}} \bigfrac{\v^* L_1 \v}{\v^* \v} \le \bigfrac{44}{\tau} \cdot \min_{\y \in \mathbbm{C}^d} \eta_{\tX}( \sgn(\y) ).\]
\end{proof}

We now state the main result of this section:

\begin{theorem}
Suppose that $G = (V=[d], E)$ is an undirected, connected, and unweighted graph (so that $W_{ij} = \chi_{E(i, j)}$) with spectral gap $\tau > 0$.  Let ${\bf u} \in \mathbbm{C}^d$ be an eigenvector of $L_1$ from \eqref{equ:ConnectLaplace} corresponding to its smallest eigenvalue, and let \[\widetilde{\bf x} = \sgn({\bf u}) \ \text{and} \ \tx_0 = \sgn(\x_0).\] Then \[\min_{\theta \in [0, 2\pi]} ||\tx - \ee^{\ii \theta} \tx_0||_2 \le 19 \bigfrac{\|\tX - \widetilde{\X}_0\|_F}{\tau \cdot \sqrt{\min_{i \in V}(\deg(i))}},\] where $\tX$ and $\widetilde{\X}_0$ are defined as per \eqref{equ:DeftildeXviaGcomp} and \eqref{equ:DeftildeXviaGpure}, respectively. %%If, in addition, $G$ is $k$-regular, then we have \[\min_{\theta \in [0, 2\pi]} ||x - \ee^{\ii \theta}u||_2 \le C \bigfrac{||A_0 - A_1||_F}{k^{1/2}\tau}.\]
\label{thm:SpecGraphPertBound}
\end{theorem}

The proof follows by combining the two following lemmas, which share the hypotheses of the theorem.  Additionally, we introduce the notation ${\bf g} \in \C^d$ and $\Lambda \in \C^{d \times d}$, where $$g_i = (\tx_0)^*_i \tx_i \quad \text{and} \quad \Lambda_{ij} = (\tX_0)^*_{ij} \tX_{ij},$$ and observe that $|g_i| = |\Lambda_{ij}| = 1$ for each $(i, j) \in E$.

\begin{lemma}\label{lem:gbound1}
Under the hypotheses of Theorem \ref{thm:SpecGraphPertBound}, there exists an angle $\theta \in [0, 2\pi]$ such that \[\tau \sum_{i \in V} \deg(i) \lvert g_i - \ee^{\ii \theta} \rvert^2 \le 2 \sum_{(i, j) \in E} \lvert g_i - g_j \rvert^2.\]
\end{lemma}

\begin{lemma}\label{lem:gbound2}
Under the hypotheses of Theorem \ref{thm:SpecGraphPertBound}, \[2\sum_{(i, j) \in E} \lvert g_i - g_j \rvert^2 \le \dfrac{356}{\tau} \lVert \tX - \tX_0 \rVert^2_F.\]
\end{lemma}

From these lemmas, the theorem follows immediately by observing $\sum_{i \in V} |g_i - \ee^{\ii \theta}|^2 = \norm{\tx - \ee^{\ii \theta} \tx_0}_2^2$.

\begin{proof}[Proof of Lemma~\ref{lem:gbound1}]
We set $\alpha = \bigfrac{\sum_{i \in V} \deg(i) g_i}{\vol(G)}$ and $w_i = g_i - \alpha$.  Then \[\mathbbm{1}^* D {\bf w} = \sum_{i \in V} \deg(i)(g_i - \alpha) = 0,\] so $D^{1/2}{\bf w}$ is orthogonal to $ D^{1/2}\mathbbm{1}$.  Noting that the null space of $L$ is spanned by $D^{1/2}\mathbbm{1}$ when $\tau > 0$, and recalling that $L \succeq 0$, we have \[\bigfrac{(D^{1/2}{\bf w})^* L (D^{1/2} {\bf w})}{{\bf w}^* D {\bf w}} \ge \min_{ \y^*D^{1/2}\mathbbm{1}=0} \bigfrac{\y^* L \y}{\y^* \y} = \tau.\]  Therefore, \[\everymath{\displaystyle} 
\begin{array}{rclcl}%
\tau {\bf w}^* D {\bf w} & \le&  {\bf w}^*(D - W) {\bf w} & = & {\bf g}^*(D - W) {\bf g}  \\
 & = & \sum_{i \in V} \deg(i) |g_i|^2 - \sum_{i \in V} g_i^* \sum_{(i,j) \in E}  g_j & = & \sum_{(i,j) \in E} (1 - g _i^* g_j) \\
 & = & \frac{1}{2} \sum_{(i, j) \in E} |g_i - g_j|^2.%
\end{array}\]%
We note that $\tau {\bf w}^* D {\bf w} = \tau \sum_{i \in V}\deg(i)|g_i - \alpha|^2$, while we seek a bound on $\sum_{i \in V} \deg(i) |g_i - \ee^{\ii \theta}|^2$.  To that end, we use the fact that $|g_i| = |\sgn(\alpha)| = 1$ to obtain $$|g_i - \sgn(\alpha)| \le |g_i - \alpha| + |\alpha - \sgn(\alpha)| \le 2|g_i - \alpha|.$$   Setting $\theta := \arg{\alpha}$, we have the stated result.
\end{proof}

\begin{proof}[Proof of Lemma~\ref{lem:gbound2}]
  Observe that for any two real numbers $a, b \in \R$, we have $\frac{1}{2} a^2 - b^2 \le (a - b)^2$. Thus, by the reverse triangle inequality we have
  \begin{equation}
    \begin{aligned}
      \sum_{(i, j) \in E}  \left(\frac{1}{2} |g_i - g_j|^2 - |\Lambda_{ij} - 1|^2\right)
      &\le \sum_{(i, j) \in E}  \left( |g_i - g_j| - |\Lambda_{ij} - 1|\right)^2 \\
      &\le \sum_{(i, j) \in E}  |g_i - \Lambda_{ij}g_j|^2 \\
      &= \sum_{(i, j) \in E}  |\tx_i - \tX_{ij} \tx_j |^2 \\
      &= 2 \vol(G) \cdot \eta_{\tX}(\tx),
    \end{aligned}
    \label{eq:gi_to_frustration}
  \end{equation}
%% \[\everymath{\displaystyle}\begin{array}{rcl}%
%% \sum_{(i, j) \in E}  \left(\frac{1}{2} |g_i - g_j|^2 - |\Lambda_{ij} - 1|^2\right) & \le & \sum_{(i, j) \in E}  \left( |g_i - g_j| - |\Lambda_{ij} - 1|\right)^2 \\%
%%  & \le & \sum_{(i, j) \in E}  |g_i - \Lambda_{ij}g_j|^2 \\%
%% %& = & \sum_{(i, j) \in E}  |(\tx_0)_i^* \tx_i - (\tx_0)_i^* (\tx_0)_j \tX_{ij}(\tx_0)_j^* \tx_j|^2 \\%
%% & = & \sum_{(i, j) \in E}  |\tx_i - \tX_{ij} \tx_j |^2 \\%
%% & = & 2 \vol(G) \cdot \eta_{\tX}(\tx),%
%% \end{array}\]
%
as the denominator of \eqref{eq:frustration} is $2\vol(G)$ whenever the entries of $\y$ all have unit modulus.

Lemma~\ref{lem:CheegerInequality} now tells us that 
\begin{equation} \begin{aligned} \sum_{(i, j) \in E}  \left(\frac{1}{2} |g_i - g_j|^2 - |\Lambda_{ij} - 1|^2\right) &\le \bigfrac{2 \cdot 44 \vol(G)}{\tau} \min_{\y \in \mathbbm{C}^d} \eta_{\tX}( \sgn(\y) ) \\&\le \bigfrac{88 \vol(G)}{\tau} \eta_{\tX}(\tx_0).\end{aligned} \label{eq:de-cheeg} \end{equation}
Moreover,%
$$\begin{array}{rcl}%
\eta_{\tX}(\tx_0) & = & \bigfrac{\sum_{(i, j) \in E} |(\tx_0)_i - \tX_{ij} (\tx_0)_j |^2}{2 \sum_{i \in V} \deg(i) |(\tx_0)_i|^2} \\%
& = & \bigfrac{\sum_{(i, j) \in E} |(\tx_0)_i (\tx_0)^*_j - \tX_{ij}|^2}{2 \vol(G)} \\%
& = & \bigfrac{ \| \widetilde{\X}_0 - \tX \|_F^2}{2 \vol(G)},%
\end{array}$$%
so that $\sum_{(i, j) \in E} \frac{1}{2} |g_i - g_j|^2 \le \frac{88}{\tau} \lVert \X_0 - \X \rVert^2_F + \sum_{(i, j) \in E} |\Lambda_{ij} - 1|^2$.  Considering also that \begin{equation} \sum_{(i, j) \in E} \abs{\Lambda_{ij} - 1}^2 = \sum_{(i, j) \in E} \abs*{\tX_{ij} - (\tX_0)_{ij}}^2 = \norm*{\tX - \tX_0}_F^2 \label{eq:Lamb=Frob}\end{equation} and $\tau \le 1$, this completes the proof.
\end{proof}

%% \begin{proof}  We begin by defining ${\bf g} \in \mathbbm{C}^d$ and $\Lambda \in \mathbbm{C}^{d \times d}$ by $g_i = (\tx_0)_i^* \tx_i$ and $\Lambda_{ij} = (\tX_0)^*_{ij} \tX_{ij} = (\tx_0)_i^* (\tx_0)_j \tX_{ij}$.  Note that $|g_i| = |\Lambda_{ij}| = 1$ holds for all $(i,j) \in E$.  Thus, by Lemma~\ref{lem:SimpGTB1} and the reverse triangle inequality, we have 
%% \[\everymath{\displaystyle}\begin{array}{rcl}%
%% \sum_{(i, j) \in E}  \left(\frac{1}{2} |g_i - g_j|^2 - |\Lambda_{ij} - 1|^2\right) & \le & \sum_{(i, j) \in E}  \left( |g_i - g_j| - |\Lambda_{ij} - 1|\right)^2 \\%
%%  & \le & \sum_{(i, j) \in E}  |g_i - \Lambda_{ij}g_j|^2 \\%
%% & = & \sum_{(i, j) \in E}  |(\tx_0)_i^* \tx_i - (\tx_0)_i^* (\tx_0)_j \tX_{ij}(\tx_0)_j^* \tx_j|^2 \\%
%% & = & \sum_{(i, j) \in E}  |\tx_i - \tX_{ij} \tx_j |^2 \\%
%% & = & 2 \vol(G) \cdot \eta_{\tX}(\tx),%
%% \end{array}\]%
%% as the denominator of $\eta_{\tX}(\y)$ is $2\vol(G)$ whenever the entries of $\y$ all have unit modulus.

%% Lemma~\ref{lem:CheegerInequality} now tells us that 
%% \[ \sum_{(i, j) \in E}  \left(\frac{1}{2} |g_i - g_j|^2 - |\Lambda_{ij} - 1|^2\right) \le \bigfrac{2 C' \vol(G)}{\tau} \min_{\y \in \mathbbm{C}^d} \eta_{\tX}( \sgn(\y) ) \le \bigfrac{2C' \vol(G)}{\tau} \eta_{\tX}(\tx_0).\] 
%% Moreover,
%% \[\begin{array}{rcl}%
%% \eta_{\tX}(\tx_0) & = & \bigfrac{\sum_{(i, j) \in E} |(\tx_0)_i - \tX_{ij} (\tx_0)_j |^2}{2 \sum_{i \in V} \deg(i) |(\tx_0)_i|^2} \\%
%% & = & \bigfrac{\sum_{(i, j) \in E} |(\tx_0)_i (\tx_0)^*_j - \tX_{ij}|^2}{2 \vol(G)} \\%
%% & = & \bigfrac{ \| \widetilde{\X}_0 - \tX \|_F^2}{2 \vol(G)}.%
%% \end{array}\]%
%% Considering also that $\sum_{(i, j) \in E} |\Lambda_{ij} - 1|^2 = \sum_{(i, j) \in E} |\tX_{ij} - (\tX_0)_{ij}|^2 = \| \tX - \tX_0 \|_F^2,$ this analysis gives 
%% \[\sum_{(i, j) \in E} |g_i - g_j|^2 \le 2 \left(\bigfrac{C'}{\tau} + 1\right) \|\tX - \widetilde{\X}_0\|_F^2.\]

%% We now set $\alpha = \bigfrac{\sum_{i \in V} \deg(i) g_i}{\vol(G)}$ and $w_i = g_i - \alpha$.  Then \[\mathbbm{1}^* D {\bf w} = \sum_{i \in V} \deg(i)(g_i - \alpha) = 0,\] so $D^{1/2}{\bf w} \perp D^{1/2}\mathbbm{1}$.  Noting that the null space of $L$ is $\Span(D^{1/2}\mathbbm{1})$ when $\tau > 0$, and recalling that $L \succeq 0$, we have \[\bigfrac{(D^{1/2}{\bf w})^* L (D^{1/2} {\bf w})}{{\bf w}^* D {\bf w}} \ge \min_{\y \in \C^d, y \perp D^{1/2}\mathbbm{1}} \bigfrac{\y^* L \y}{\y^* \y} = \tau.\]  Therefore, \[\everymath{\displaystyle} \begin{array}{rcl}%
%% \tau {\bf w}^* D {\bf w} \le {\bf w}^*(D - W) {\bf w} & = & ({\bf g} - \alpha\mathbbm{1})^*(D - W)( {\bf g} - \alpha\mathbbm{1}) \\%
%%  & = & {\bf g}^*(D - W) {\bf g} \\%
%%  & = & \sum_{i \in V} \deg(i) |g_i|^2 - \sum_{i \in V} g_i^* \sum_{(i,j) \in E}  g_j \\%
%%  & = & \sum_{(i,j) \in E} (1 - g_i^* g_j) \\%
%%  & = & \frac{1}{2} \sum_{(i ,j) \in E} (2 - g_i^* g_j - g_j^* g_i) \\%
%%  & = & \frac{1}{2} \sum_{(i, j) \in E} |g_i - g_j|^2 \\%
%%  & \le & \left(\bigfrac{C'}{\tau} + 1\right) \|\tX - \widetilde{\X}_0\|_F^2.%
%% \end{array}\]%

%% To finish, we may now note that $\tau {\bf w}^* D {\bf w} = \tau \sum_{i \in V}\deg(i)|g_i - \alpha|^2$.  By Lemma~\ref{lem:SimpGTB2}, then, we have 
%% \[\bigfrac{\tau}{2} \sum_{i \in V} \deg(i) \left| g_i - \bigfrac{\alpha}{|\alpha|} \right|^2 \le \tau {\bf w}^* D {\bf w} \le \left(\bigfrac{C'}{\tau} + 1\right) \|\tX - \widetilde{\X}_0\|_F^2.\]  
%% Recalling that $g_i = (\tx_0)_i^* \tx_i$, setting $\ee^{\ii\theta} = \bigfrac{\alpha}{|\alpha|}$, and rearranging now gives 
%% \[\sum_{i \in V} \left | \tx_i - \ee^{\ii \theta}(\tx_0)_i \right|^2 \le \bigfrac{2}{\tau \min_{i \in V}(\deg(i))} \left(\bigfrac{C'}{\tau} + 1\right)  \|\tX - \widetilde{\X}_0\|_F^2.\]  
%% %%If $G$ is not $k$-regular, we bound $\min(\deg(i))$ by $1$ ($G$ is connected; in particular, there are no isolated vertices), otherwise we osberve $\min(\deg(i)) = k$, and the desired result follows.
%% We obtain our final form of the bound by noting that $\tau \leq 2$ will always hold for $d \geq 2$ (see, e.g., Lemma 1.7 of \cite{chungspectral}).
%% \end{proof}

We may now use Theorem~\ref{thm:SpecGraphPertBound} to produce a perturbation bound for our banded matrix of phase differences $\widetilde{\X}_0$.% from \eqref{equ:MatrixofPhases}.

\begin{corollary}\label{cor:GenBoundv2}
Let $\tX_0$ be the matrix in \eqref{eq:X_0}, $\tx_0$ be the vector of true phases \eqref{eq:X_0}, and $\tX$ be as in line 3 of Algorithm~\ref{alg:phaseRetrieval1} with $\tx = \sgn({\bf u})$ where ${\bf u}$ is the top eigenvector of $\widetilde{X}$. Suppose that 
$\Vert \tX_0 - \tX \Vert_F \le \eta \Vert \tX_0 \Vert_F$ for some $\eta>0$.  Then
\[\mintheta \norm{\tx_0 - \eit \tx}_2 \le 12 \bigfrac{\eta d^\frac{5}{2}}{\delta^{2}}.\]
\end{corollary}

\begin{proof}
 We apply Theorem~\ref{thm:SpecGraphPertBound} with the unweighted and undirected graph $G = (V, E)$, where $V = [d]$ and $E = \{(i, j) : |i - j| \mod d < \delta\}$.  Observe that $G$ is also connected and $(2\delta - 1)$-regular so that $\min_{i \in V}(\deg(i)) = 2\delta - 1$.  The spectral gap of $G$ is $\tau > \frac{\pi^2}{6} \delta^2 / d^2 > 0$ by Corollary~\ref{cor:Gspectrum}.  We know that $\| \widetilde{X}_0 \|_F = \sqrt{d(2\delta - 1)}$, so that $\| \tX_0 - \tX \|_{F} \le \eta \sqrt{d(2\delta - 1)}$.  Finally, if ${\bf u}$ is the top eigenvector of $\widetilde{X}$ then it will also be an eigenvector of $L_1$ corresponding to its smallest eigenvalue since, here, $L_1 = I - \frac{1}{2 \delta - 1} \tX $.

Combining these observations we have \[\min_{\theta\in[0,2\pi]} \Vert \tx_0 - \mathbbm{e}^{\mathbbm{i}\theta} \tx \Vert_2 \le 19 \bigfrac{\eta (d (2 \delta - 1))^{1/2}}{\pi^2 / 6 \cdot \delta^2 / d^2 \cdot (2 \delta - 1)^{1/2}} \le 12 \bigfrac{\eta d^{5/2}}{\delta^2}.\]
\end{proof}

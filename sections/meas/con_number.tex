Now that we have characterized this collection of spanning families, we are interested in the condition number for solving the linear system $y = \mathcal{A}(T_{\delta}(xx^*)) + \eta$ to estimate $T_\delta(xx^*)$.  We begin by introducing the main result of this section:

\begin{proposition}
  Let $\{m_j\}_{j = 1}^D \subset \C^d$ be a local Fourier measurement system with support $\delta$, mask $\gamma$, and modulation index $K$, where $D = \min(d, 2 \delta - 1)$.  Let $\Ac$ be the associated measurement operator as in \eqref{eq:meas_op}, with canonical matrix representation $A$ as in \eqref{eq:meas_mat}.

If we additionally assume that $2 \delta - 1 \le d$ and $K = 2 \delta - 1,$ then the condition number of $\mathcal{A}$ is \begin{equation}\kappa(\mathcal{A}) = \dfrac{\max\limits_{m \in [\delta]_0, j \in [d]} \lvert F_d (\gamma \circ S^{-m} \gamma)_j \rvert}{\min\limits_{m \in [\delta]_0, j \in [d]} \lvert F_d (\gamma \circ S^{-m} \gamma)_j \rvert}.\label{eq:clean_cond}\end{equation}  Otherwise, if $2 \delta - 1 > d$ or $K > 2 \delta - 1$, we may bound the condition number by \begin{equation}\kappa(\mathcal{A}) \le \dfrac{\max\limits_{m \in [\delta]_0, j \in [d]} \lvert F_d (\gamma \circ S^{-m} \gamma)_j \rvert}{\min\limits_{m \in [\delta]_0, j \in [d]} \lvert F_d (\gamma \circ S^{-m} \gamma)_j \rvert} \kappa(\tF_K), \label{eq:messy_cond}\end{equation} where $\tF_K \in \C^{D \times D}$ is the $D \times D$ principal submatrix of $F_K$.
\label{prop:span_fam_cond}
\end{proposition}

\subsection{Interleaving operators and circulant structure}
\label{sec:interlemma}

To set the stage for the proof, we introduce a certain collection of permutation operators and study their interactions with circulant and block-circulant matrices.  The structure we identify here will be of much use to us in unraveling the linear systems we encounter in our model for phase retrieval with local correlation measurements.

To this end, we introduce the \emph{interleaving operators} $P^{(d, N)} : \C^{dN} \to \C^{dN}$ for any $d, N \in \N$, each of which is a permutation defined by \begin{equation} (P^{(d, N)} v)_{(i - 1)N + j} = v_{(j - 1)d + i}.\label{eq:interleave_def}\end{equation}  We can view this is beginning with $v \in C^{dN}$ written as $N$ blocks of $d$ entries, and interleaving them into $d$ blocks each of $N$ entries.  Additionally, for $\ell, N_1, N_2 \in \N, v \in \C^{\ell N_1}, k \in [\ell],$ and $H \in \C^{\ell N_1 \times N_2}$, we define the block circulant operator $\circop^{N_1}$ by
\begin{align*}
  \circop_k^{N_1}(v) &= \begin{bmatrix} v & S^{N_1} v & \cdots & S^{(k - 1)N_1} v \end{bmatrix} \\
  \circop_k^{N_1}(H) &= \begin{bmatrix} H & S^{N_1} H & \cdots & S^{(k - 1) N_1}H \end{bmatrix},
\end{align*}
where, as with $\circop(\cdot)$, when we omit the subscript we define $\circop^{N_1}(H) = \circop_\ell^{N_1}(H)$ and $\circop^{N_1}(v) = \circop_\ell^{N_1}(v)$.  We now proceed with the following lemmas; the first establishes the inverse of $P^{(d, N)}$.

\begin{lemma}
  For $d, N \in \N,$ we have \[(P^{(d, N)})^{-1} = P^{(d, N) *} = P^{(N, d)}.\]
  \label{lem:interleave_inverse}
\end{lemma}

\begin{proof}[Proof of \cref{lem:interleave_inverse}]
  To prove the statement, we simply take $v \in \C^{d N}$ and calculate, for $i \in [d], j \in [N]$,
  \begin{align*}
    (P^{(d, N)} P^{(N, d)} v)_{(i - 1) N + j} &= (P^{(d, N)} (P^{(N, d)} v))_{(i - 1) N + j} \\
    &= (P^{(N, d)} v)_{(j - 1) d + i} \\
    &= v_{(i - 1) N + j},
  \end{align*}
  with these equalities coming from the definition in \eqref{eq:interleave_def}.  
\end{proof}

We now observe some useful ways in which the interleaving operators commute with the construction of circulant matrices.

\begin{lemma}
  Suppose $v_i, v_{ij} \in \C^k, w_j \in \C^{k N_1}$ for $i \in [N_1], j \in [N_2]$ and
  \begin{gather*}
    M_1 = \begin{bmatrix} \circop(v_1) \\ \vdots \\ \circop(v_{N_1}) \end{bmatrix},\quad
    M_2 = \begin{bmatrix} \circop^{N_1}(w_1) & \cdots & \circop^{N_1}(w_{N_2}) \end{bmatrix},\ \text{and} \\
    M_3 = \begin{bmatrix} \circop(v_{11}) & \cdots & \circop(v_{1 N_2}) \\ \vdots & \ddots & \vdots \\ \circop(v_{N_1 1}) & \cdots & \circop(v_{N_1 N_2}) \end{bmatrix}.\end{gather*}
  Then
  \begin{align}
    P^{(k, N_1)} M_1 &= \circop^{N_1}\left(P^{(k, N_1)} \begin{bmatrix} v_1 \\ \vdots \\ v_{N_1} \end{bmatrix}\right) \label{eq:M_1} \\
    M_2 P^{(k, N_2)*} &= \circop^{N_1}\left(\begin{bmatrix} w_1 & \cdots & w_{N_2} \end{bmatrix}\right) \label{eq:M_2} \\
    P^{(k, N_1)}M_3P^{(k, N_2)*} &= \circop^{N_1}\left(P^{(k, N_1)} \begin{bmatrix} v_{11} & \cdots & v_{1 N_2} \\ \vdots & \ddots & \vdots \\ v_{N_1 1} & \cdots & v_{N_1 N_2} \end{bmatrix}\right). \label{eq:M_3}
  \end{align}
  \label{lem:interleave}
\end{lemma}

\begin{proof}[Proof of lemma \ref{lem:interleave}]
  We index the matrices to check the equalities.  For \eqref{eq:M_1}, we have \begin{align*}
    (P^{(k, N_1)} M_1)_{(a-1)N_1 + b, j} &= (M_1)_{(b - 1) k + a, j} \\ &= \begin{bmatrix} S^{j - 1}v_1 \\ \vdots \\ S^{j - 1} v_{N_1} \end{bmatrix}_{(b - 1)k + a} \\ &= (S^{j - 1}v_b)_a = (v_b)_{a + j - 1}
  \end{align*}
  and
  \begin{align*}
    \circop^{N_1}\left(P^{(k, N_1)} \begin{bmatrix} v_1 \\ \vdots \\ v_{N_1} \end{bmatrix}\right)_{(a-1)N_1 + b, j} &= \left(P^{(k, N_1)} \begin{bmatrix} v_1 \\ \vdots \\ v_{N_1} \end{bmatrix}\right)_{(a - 1)N_1 + b + (j-1)N_1} \\
    &= %\begin{bmatrix} v_1 \\ \vdots \\ v_{N_1} \end{bmatrix}_{(b-1)k + a + j - 1} = 
    (v_b)_{a + j - 1}
  \end{align*}
  For \eqref{eq:M_2}, we have
%  \begin{align*}
 \[(P^{(k, N_2)} M_2^*)_{(a - 1)N_2 + b, j} = (M_2)_{j, (b - 1) k + a} = (w_b)_{j + (a - 1)N_1}\]
%  \end{align*}
  and
  \[\left(\circop^{N_1}\left(\begin{bmatrix} w_1 & \cdots & w_{N_2} \end{bmatrix}\right)\right)_{j, (a - 1)N_2 + b} = (S^{N_1(a - 1)} w_b)_j = (w_b)_{j + N_1(a - 1)}\]

  \eqref{eq:M_3} follows immediately by combining \eqref{eq:M_1} and \eqref{eq:M_2}.
\end{proof}

\Cref{lem:interkron} introduces a few useful identities relating the interleaving operators to kronecker products.

\begin{lemma}
  For $v \in \C^N, V = \rowmat{V}{1}{\ell} \in \C^{N \times \ell}, A = \rowmat{A}{1}{m} \in \C^{d \times m}$, and $B_i \in \C^{m \times k}, i \in [\ell]$, we have
  \begin{align}
    P^{(d, N)} (v \kron A) &= A \kron v
    \label{eq:interkron_vec} \\
    P^{(d, N)} (V \kron A) &= \rowmat{A \kron V}{1}{\ell}
    \label{eq:interkron_mat} \\
    P^{(d, N)} (V \kron A) P^{(\ell, m)} &= A \kron V
    \label{eq:interkron_swap} \\
    (V \kron A) \diagmat{B}{1}{\ell} &= \rowmatfun{V_@ \kron A B_@}{1}{\ell}
    \label{eq:kron_diag}
  \end{align}
  \label{lem:interkron}
\end{lemma}

\begin{proof}[Proof of \cref{lem:interkron}]
  For \eqref{eq:interkron_vec}, we see that, for $i, j, k \in [d] \times [N] \times [m]$, we have
  \begin{align*}
    (P^{(d, N)} v \otimes A)_{(i - 1) N + j, k} &= (v \otimes A)_{(j - 1) d + i, k} \\
    &= v_j A_{i k}, \ \text{while} \\
    (A \kron v)_{(i - 1) N + j, k} &= A_{i k} v_j,
  \end{align*}
  and \eqref{eq:interkron_mat} follows by considering that $V \otimes A = \rowmatfun{V_@ \kron A}{1}{\ell}.$  To get \eqref{eq:interkron_swap}, we trace the positions of columns, considering that $(V \kron A) e_{(i - 1) m + j} = V_j \kron A_i$.  From \eqref{eq:interkron_mat}, we observe that $P^{(d, N)} (V \kron A) e_{(i - 1) m + j} = A_j \kron V_i,$ so \begin{align*}
    P^{(d, N)} (V \kron A) P^{(m, \ell)} e_{(j - 1) \ell + i} &= P^{(d, N)} (V \kron A) e_{(i - 1) m + j} \\
    &= A_j \kron V_i = (A \kron V) e_{(j - 1) \ell + i}.
  \end{align*}
 As for \eqref{eq:kron_diag}, we remark that \begin{gather*} (V \kron A) \diagmat{B}{1}{\ell}%% \begin{bmatrix} B_1 & 0 & \cdots & 0 \\ 0 & \ddots &  & \vdots \\ \vdots & & \ddots & 0 \\ 0 & \cdots & 0 & B_\ell \end{bmatrix}
    = (V \kron A) \rowmatfun{e^\ell_@ \kron B_@}{1}{\ell}  \\ = \rowmatfun{(V \kron A) (e_@^\ell \kron B_@)}{1}{\ell} = \rowmatfun{V_@ \kron A B_@}{1}{\ell},\end{gather*} as desired.
\end{proof}

The following lemma is a standard result (e.g., Theorem 13.26 in \cite{laub2004matrix}) regarding the kronecker product.

\begin{lemma}
  We have $\vec(A B C) = (C^T \kron A) \vec(B)$ for any $A \in \C^{m \times n}, B \in \C^{n \times p}, C \in \C^{p \times k}.$
  \label{lem:kronvec}
\end{lemma}
The next lemma generalizes the diagonalization of circulant matrices, stated in \eqref{eq:circ_dft_diag}, for block circulant matrices.

\begin{lemma}
  Suppose $V \in C^{k N \times m}$, then $\circop^N(V)$ is block diagonalizable by \[\circop^N(V) = \left(F_k \otimes I_N\right) \left(\diag(M_1, \ldots, M_k)\right) \left(F_k \otimes I_m\right)^*,\] where \[\sqrt{k}\left(F_k \otimes I_N\right)^* V = \begin{bmatrix} M_1 \\ \vdots \\ M_k \end{bmatrix}, \quad \text{or} \quad M_j = \sqrt{k} (f_j^k \otimes I_N)^* V\] \label{lem:circ_diag}
\end{lemma}

\begin{proof}[Proof of lemma \ref{lem:circ_diag}]
  We set $V_i$ to be the $k \times m$ blocks of $V$ such that $V^* = \rowmat{V^*}{1}{k}$ and begin by observing that, for $u \in \C^k$ and $W \in \C^{m \times p}$, the $\ell\th$ $k \times p$ block of $\circop^N(V)(u \otimes W)$ is given by \[\left(\circop^N(V)(u \otimes W)\right)_\ell = \sum_{i = 1}^k u_i (S^{N (i - 1)}V)_\ell W = \sum_{i = 1}^k u_i V_{\ell - i + 1} W.\]  Taking $u = f_j^k$ and $W = I_m$, this gives \begin{align*} \left(\circop^N(V)(f_j^k \otimes I_m)\right)_\ell &= \frac{1}{\sqrt{k}}\sum_{i = 1}^k \omega_k^{(j - 1) (i - 1)} V_{\ell - i + 1} I_m \\ &= \frac{1}{\sqrt{k}} \omega_k^{(j - 1) (\ell - 1)} \sum_{i = 1}^k \omega_k^{-(j - 1)(i - 1)} V_i \\ &= (f_j^k)_\ell \left(\sqrt{k} (f_j^k \otimes I_N)^* V \right) = (f_j^k)_\ell M_j. \end{align*}  This relation is equivalent to having \[\circop^N(V) (f_j^k \otimes I_m) = (f_j^k \otimes M_j) = (f_j^k \otimes I_N) M_j,\] which is the statement of the lemma.
\end{proof}

Lemma \ref{lem:circ_diag} immediately gives the following corollary regarding the conditioning of $\circop^N(V)$, with which we return to considering spanning families of masks.

\begin{corollary}
  With notation as in lemma \ref{lem:circ_diag}, the condition number of $\circop^N(V)$ is \[\dfrac{\max\limits_{i \in [k]} \sigma_{\max} (M_i)}{\min\limits_{i \in [k]} \sigma_{\min} (M_i)}.\] \label{cor:circ_diag_condition}
\end{corollary}

\subsection{Proof of \cref{prop:span_fam_cond}}

To begin the proof of \cref{prop:span_fam_cond}, we apply the results of \cref{sec:interlemma} to the case of the measurement operator for a family of masks, as defined in \cref{sec:span_fam}.

\begin{proposition}
  Given a family of masks $\{m_j\}_{j \in [D]}$ of support $\delta \le \frac{d + 1}{2}$, we define $g_m^j = \diag(m_j m_j^*, m),$ \[H = P^{(d, D)} \cornmatfun{R g^@r_@c}{1}{D}{1 - \delta}{\delta - 1}%% \begin{bmatrix} R g_{1 - \delta}^1 & \cdots & R g_{\delta - 1}^1 \\ \vdots & \ddots & \vdots \\ R g_{1 - \delta}^D & \cdots & R g_{\delta - 1}^D \end{bmatrix}
  ,\] and $M_j = \sqrt{d}\left(f_j^d \otimes I_D\right)^* H$.  Then the condition number of $\mathcal{A}$ as defined in \eqref{eq:meas_op} is \[\kappa(\mathcal{A}) = \dfrac{\max\limits_{i \in [d]} \sigma_{\max} (M_i)}{\min\limits_{i \in [d]} \sigma_{\min} (M_i)}.\] \label{prop:meas_cond}
\end{proposition}

\begin{proof}
  We consider the rows of the matrix $A$ representing the measurement operator $\mathcal{A}$, defined in \eqref{eq:meas_mat} and \eqref{eq:meas_op}.  We vectorize $X \in T_\delta(\C^{d \times d})$ by its diagonals with $\Dc_\delta$, as in \eqref{eq:diag_vec} and set $\chi_m = \diag(X, m), m = 1 - \delta, \ldots, \delta - 1$.  Each measurement then looks like
  \begin{align*}
    \mathcal{A}(X)_{(\ell, j)} &= \langle S^{\ell} m_j m_j^* S^{-\ell}, X \rangle \\
    &= \sum_{m = 1 - \delta}^{\delta - 1} \langle S^{\ell} g_m^j, \chi_m \rangle,
  \end{align*}
  so that the definition of $A$ in \eqref{eq:meas_mat} immediately yields its $(j - 1) d + \ell\th$ row as $\rowmatfun{g_@^{j*} S^{1 - \ell}}{1 - \delta}{\delta - 1}$.  Transposing this expression, we see that the $(j - 1)d + 1\st$ through $(j - 1) d + d\th$ rows of $A$ compose $\rowmatfun{\circop(g^j_@)^*}{1 - \delta}{\delta - 1}$. %% \[\begin{bmatrix} S^{\ell - 1} g_{1 - \delta}^j \\ \vdots \\ S^{\ell - 1} g_{\delta - 1}^j \end{bmatrix}^*.\]  
  Together with $\circop(v)^* = \circop(Rv)$, this determines $A$ to be the block matrix given by \[A = \cornmatfun{\circop(g_@r^@c)^*}{1}{D}{1 - \delta}{\delta - 1} = \cornmatfun{\circop(R g_@r^@c)}{1}{D}{1 - \delta}{\delta - 1},\] which may be transformed, by \eqref{eq:M_3} of \cref{lem:interleave}, to \begin{equation}P^{(d, D)} A P^{(d, 2 \delta - 1)*} = \circop^D\left(P^{(d, D)} \cornmatfun{R g_@c^@r}{1}{D}{1 - \delta}{\delta - 1} \right) = \circop^D(H). \label{eq:interleaved_meas}\end{equation}

%We label the $D \times 2\delta - 1$ blocks of $H$ by $H^* = \begin{bmatrix} H_1^* & \cdots & H_d^* \end{bmatrix}$, so that $(H_\ell)_{ij} = (R g_{j - \delta}^i)_\ell = (g_{j - \delta}^i)_{2 - \ell}$.
Quoting corollary \ref{cor:circ_diag_condition} establishes the proposition.
\end{proof}

We are now able to prove proposition \ref{prop:span_fam_cond}.

\begin{proof}[Proof of Proposition \ref{prop:span_fam_cond}]
  For the moment, we assert that $D = 2 \delta - 1 \le d$ and set $\tF_K \in \C^{2 \delta - 1 \times 2 \delta - 1}, (\tF_K)_{ij} = \frac{1}{\sqrt{K}}\omega_K^{(i-1)(j-\delta)}$ to be the principal submatrix of $\sqrt{K} \diag(f^K_{2 - \delta}) F_K$.  In this case, $g_m^j = \diag(m_j m_j^*, m) = \omega_K^{m(j - 1)} g_m$, as in \eqref{eq:gam_diag}.  Therefore, we label the $2 \delta - 1 \times 2 \delta - 1$ blocks of $H$ by $H^* = \begin{bmatrix} H_1^* & \cdots & H_d^* \end{bmatrix}$, so that \[(H_\ell)_{ij} = (R g_{j - \delta}^i)_\ell = \omega_K^{(i - 1)(j - \delta)}(R g_{j - \delta})_\ell\] and $M_\ell = \sum_{k = 1}^d \omega_d^{(\ell - 1)(k - 1)} H_k,$ giving \begin{align*} (M_\ell)_{ij} &= \sum_{k = 1}^d \omega_d^{(\ell - 1)(k - 1)} (H_k)_{ij} = \omega_K^{(i - 1)(j - \delta)} \sum_{k = 1}^d \omega_d^{(\ell - 1)(k - 1)} (Rg_{j - \delta})_k \\ &= \omega_K^{(i - 1)(j - \delta)} (F_d^* g_{j - \delta})_\ell. \end{align*}  In other words, \begin{equation} M_\ell = \sqrt{K} \tF_K \diag(f_\ell^{d*} g_{1 - \delta},\, \ldots\, , f_\ell^{d*} g_{\delta - 1}). \label{eq:block_diag_components} \end{equation}  If $K = 2 \delta - 1$, then $\tF_K$ is unitary, and the singular values of $M_\ell$ are $\{\sqrt{K} f_\ell^{d *} g_j\}_{j = 1 - \delta}^{\delta - 1}$.  Recognizing that $S^j g_j = g_{-j}$, then proposition \ref{prop:meas_cond} takes us to \eqref{eq:clean_cond}.

  If $D = 2 \delta - 1 < K$, then the argument remains unchanged, except that the singular values of $M_\ell$, instead of being known explicitly, are bounded above and below by $\max\limits_{|j| < \delta} |f_\ell^{d *} g_j| \sigma_{\max}(\tF_K)$ and $\min\limits_{|j| < \delta} |f_\ell^{d *} g_j| \sigma_{\min}(\tF_K)$ respectively, which gives the more general result of \eqref{eq:messy_cond}.

  If $2 \delta - 1 > d = D$, then, by considering that the argument of \cref{prop:meas_cond} depended only on the indices of the diagonals under consideration.  By a similar argument, however, we may obtain \[A = \cornmatfun{\circop(R g_@r^@c)}{0}{d - 1}{1}{d},\] and a similar application of \eqref{eq:M_3} gives that \[P^{(d, d)} A P^{(d, 2 \delta - 1)*} = \circop^d\left( P^{(d, d)} \cornmatfun{R g_@r^@c}{0}{d - 1}{1}{d} \right).\]  Setting \[H = P^{(d, d)} \cornmatfun{R g_@r^@c}{0}{d - 1}{1}{d},\] and defining $H_\ell \in \C^{d \times d}$ by $H^* = \rowmat{H^*}{1}{d}$, %% then instead of using diagonals $1 - \delta, \ldots, \delta - 1$, we use diagonals $0, 1, \ldots, d - 1$.  This change propagates from \eqref{eq:vectorized_meas} to \eqref{eq:interleaved_meas}, so that
  we have \[(H_\ell)_{ij} = \omega_K^{(i - 1)(j - 1)} (R g_{j - 1})_\ell \quad \text{and} \quad (M_\ell)_{ij} = \omega_K^{(i - 1)(j - 1)} (F_d^* g_{j - 1})_\ell,\] giving $M_\ell = \sqrt{K} \mathcal{R}_{d \times d}(F_K) \diag(f_\ell^{d*} g_0,\, \ldots\, , f_\ell^{d*} g_{d - 1})$, which immediately gives us \eqref{eq:messy_cond}.  We remark that indexing only over the diagonals $m \in [\delta]_0$ in \eqref{eq:messy_cond} suffices, again because $S^j g_j = g_{-j}$, so having $2 \delta - 1 > d$ makes $1 - \delta, \ldots, -1$ redundant.
  
\end{proof}

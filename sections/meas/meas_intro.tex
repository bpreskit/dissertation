In \Cref{ch:base_model}, we proposed the algorithm for robustly solving phase retrieval whose analysis and extension forms the basis of this dissertation.  This algorithm, stated in \Cref{alg:phaseRetrieval1}, operated in two steps: the first step is to solve a linear system, obtained by recasting the magnitude-only linear measurements $y_{(\ell, j)} = \abs{\inner{x_0, S^{\ell} m_j}}^2 + \eta_{j \ell}$ as linear measurements on the space of Hermitian matrices, by rewriting \[\abs{\inner{x_0, S^{\ell} m_j}}^2 = \Tr\left(S^{\ell} m_j m_j^* S^{- \ell} x_0 x_0^*\right) = \inner{S^{\ell} m_j m_j^* S^{- \ell}, x_0 x_0^*}.\]  By design, the ``vectors'' $\{S^{\ell} m_j m_j^* S^{- \ell}\}$ are all contained in the subspace $T_\delta(\H^d)$ of $\H^d$ (defined in \eqref{eq:T_delta}), where $d$ is the ambient dimension (meaning $x_0, m_j \in \Cd$) and $\delta$ is the support size of the masks (so $\supp(m_j) \subset [\delta]$).  Hence, we used our measurements to solve for (an estimate of) the projection of $x_0 x_0^*$ onto $T_\delta(\H^d)$, namely $T_\delta(x_0 x_0^* + N) =: X$.

After the linear step, the second step is recovering $x_0$ from $X$.  We accomplish this by inferring the magnitudes of $x_0$'s entries from the main diagonal of $X$ (as the main diagonal is preserved by the projection $T_\delta$) and finding their relative phases through an angular synchronization problem (see \Cref{sec:Perturb,ch:ang_sync}).

The subject of this chapter is to study in more detail the linear system solved in the first step.  Most crucially, we consider that, in the work of \Cref{ch:base_model}, we only produced two examples of collections of vectors $\{m_j\}_{j \in [2 \delta - 1]} \subset \Cd$ such that this linear system was invertible.  Considering that one of the major contributions of our algorithm is that it admits a measurement model that somewhat replicates laboratory conditions, our knowledge of which vectors are compatible with our algorithm and the theory built for it is critical in promoting the applicability of this work.  Therefore, in \Cref{sec:span_fam}, we fully characterize a broad class of familes of masks -- whose design is, notably, motivated by the application of ptychography, described in \Cref{sec:conn_pty} -- that are guaranteed to produce an invertible linear system of the form in \eqref{eq:linear}.  The basic idea of \Cref{sec:span_fam} is to generalize Example 1 of \Cref{sec:MeasMatrix}, stated in \cref{eq:MeasDef}, by abstracting out the term $\frac{\ee^{-n/a}}{\sqrt[4]{2\delta -1}}$ and considering what ``base vectors'' $\gamma \in \Rd$ will produce spanning families of masks when $m_j$ is taken to be $m_j = f_j^K \circ \gamma$, for some $K \in \N$.  In \Cref{prop:span_fam}, we describe conditions on $\gamma$ and $K$ which are both necessary and sufficient to produce an invertible linear system, providing a satisfying answer to this inquiry.

In \Cref{sec:con_number}, we analyze the conditioning of the linear systems produced by this class of mask families.  We recall that the recovery guarantees of \Cref{sec:recov_guar}, most notably \Cref{Cor:RecovRes}, rely on the condition number $\kappa$ of this linear system.  Indeed, any result guaranteeing the robustness of our algorithm must depend on $\kappa$, as the linear solve, along with whatever noise is inflated or compressed by it, feeds directly into the magnitude estimation and angular synchronization methods of the recovery step.  Fortunately, in \Cref{prop:span_fam_cond}, we are able to calculate the condition number of this linear system exactly whenever the support size of the masks $\delta$ satisfies $2 \delta - 1 \le d$ (which includes the vast majority of cases; typically we assume $\delta \ll d$), and provide an estimate that covers all other cases.

We consider the act of inverting $\Ac$ from a practical perspective in \Cref{sec:meas_expl_inv}.  We write its inverse explicitly and analyze the runtime of calculating $\Ac^{-1}(y)$ in \Cref{sec:inv_runtime}.  In \Cref{sec:dist_var}, we analyze the variance of the individual entries of $\Ac^{-1}(y)$ when the measurements are exposed to uniform, Gaussian noise.  In \Cref{sec:span_fam_ex}, we provide a few examples of explicit $\gamma \in \Rd$ that are proven to satisfy the conditions to span $T_\delta(\H^d)$, and finally, we illustrate the impact these results with numerical studies in \Cref{sec:span_fam_num}.

Before we begin these analyses, we introduce and unify some definitions and notational elements that will make discussion of the mathematical details more convenient.

\begin{definition}
  We say that $\{m_j\}_{j = 1}^D \subset \C^d$ is a \emph{local measurement system} or \emph{family of masks} of support $\delta$ if $1 \in \supp(m_j)$ and $\supp(m_j) \subset [\delta]$ for each $j$. \label{def:loc_meas}
\end{definition}

\begin{definition}
  Let $\{m_j\}_{j = 1}^D \subset \C^d$ be a local measurement system of support $\delta$.  If each $m_j$ satisfies $m_j = \Rc_d(\sqrt{K} f_j^K) \circ \gamma$ for some $K \ge \max(\delta, D), \gamma \in \C^d$ satisfying $\supp(\gamma) = [\delta]$, then we call $\{m_j\}_{j = 1}^D$ a \emph{local Fourier measurement system} of support $\delta$ with mask $\gamma$ and modulation index $K$.  If $K = D = 2 \delta - 1$, then we simply refer to $\{m_j\}_{j = 1}^D$ as a \emph{local Fourier measurement system} of support $\delta$ with mask $\gamma$.  We add that, if we say that $\{m_j\}_{j = 1}^D$ is a local Fourier measurement system with support $\delta$ and mask $\gamma$, this implies an assertion that $\supp(\gamma) = [\delta]$. \label{def:loc_four_meas}
\end{definition}

\begin{definition}
  Given a local measurement system $\{m_j\}_{j = 1}^D$ in $\C^d$, the associated \emph{lifted measurement system} is the set $\mathcal{L}_{\{m_j\}} = \{S^{\ell} m_j m_j^* S^{- \ell}\}_{(\ell, j) \in [d]_0 \times [D]} \subset \C^{d \times d}$. \label{def:lifted_meas}
\end{definition}

\begin{definition}
  We say that a family of masks $\{m_j\}_{j = 1}^D \subset \C^d$ of support $\delta$ is a \emph{spanning family} if $\Span \Lc_{\{m_j\}} = T_\delta(\H^d)$%% $\Span \{S^\ell m_j m_j^* S^{-\ell}\}_{(\ell, j) \in [d]_0 \times [D]} = T_\delta(\H^d)$
  . \label{def:span_fam}
\end{definition}

\begin{definition}
  Given a local measurement system $\{m_j\}_{j = 1}^S$, the \emph{measurement operator} associated with these vectors is the operator
  \begin{gather}
    \mathcal{A} : T_\delta(\C^{d \times d}) \to \C^{[d]_0 \times [D]} \nonumber \\
    \mathcal{A}(X)_{(\ell, j)} = \langle S^{\ell} m_j m_j^* S^{-\ell}, X \rangle. \label{eq:meas_op}
  \end{gather}
  The \emph{canonical matrix representation} of $\Ac$ is the matrix $A \in \C^{d D \times d (2 \delta - 1)},$ defined by
  \begin{equation}
    \left(A \colmatfun{\diag(X, @)}{1 - \delta}{\delta - 1}\right)_{(j - 1) d + \ell} = \Ac(X)_{(\ell - 1, j)}.
    \label{eq:meas_mat}
  \end{equation}
  For convenience, we define the \emph{diagonal vectorization operator} $\Dc_I : \C^{d \times d} \to \C^{\abs{I} d}$ for any subset $\{m_i\}_{i = 1}^{\abs{I}} = I \subset [d]$ and $\Dc_k : \C^{d \times d} \to \C^{(2 k - 1) d}$ for any integer $k \le \frac{d + 1}{2}$ by
  \begin{align}
    \Dc_I(X) &= \colmatfun{\diag(X, m_@)}{1}{\abs{I}}
    \label{eq:diag_vec_set} \\
    \Dc_k(X) = \Dc_{[2 k - 1]_{1 - k}}(X) &= \colmatfun{\diag(X, @)}{1 - k}{k - 1},
    \label{eq:diag_vec}
  \end{align}
  so that \eqref{eq:meas_mat} becomes $A \Dc_{\delta} (X)_{(j - 1) d + \ell} = \Ac(X)_{(\ell, j)}$.  We remark that $\Dc_k$ is invertible on $T_k(\C^{d \times d})$, and for $v \in \C^{d (2 k - 1)}$, we use $\Dc_k^{-1}(v)$ to represent the matrix in $T_k(\C^{d \times d})$ whose diagonals are given by the $2k - 1$ distinct $d$-length blocks of $v$.
\end{definition}



%% \section*{Preliminaries}

%% \begin{itemize}
%% \item Indices of matrices in $\C^{d \times d}$ and vectors in $\C^d$ are always taken modulo $d$.
%% \item For $k \in \N, n \in \Z, [k]_n = \{n, n + 1, \ldots, n + k - 1\}$ and $[k] = [k]_1$.
%% \item $S_d \in \R^{d \times d}$ is the $d \times d$ shift operator, such that $(S_d \x)_i = \x_{i - 1}$.  Typically we imply the subscript by context, writing $S$.
%% \item $R \in \R^{d \times d}$ is the operator that reverses a vector's entries, leaving the first entry fixed.  Namely, $(R \x)_i = \x_{2 - i}$.
%% \item Given $\x \in \C^d$ and $k \in [d], \circop_k(\x) \in \C^{d \times k}$ denotes the first $k$ columns of the circulant matrix whose first column is $\x$.  In particular, $\circop_k(\x) e_i = S^{i - 1} \x$ for $i \in [k]$.  When the subscript is omitted, $\circop(\x) := \circop_d(\x)$.
%% \item $\omega_d := \ee^{\frac{2 \pi \ii}{d}}$ is the $d^{\text{th}}$ root of unity.  When context permits, $d$ is implied and we use just $\omega$.
%%   \item For $i, n \in \N, e_i^n \in \R^n$ is the $i^{\text{th}}$ column of the $n \times n$ identity matrix.  When context permits, $n$ is implied and we write $e_i$.  In particular, whenever $e_i$ is used in a matrix multiplication, $n$ is taken to be appropriate so that the multiplication is legal.
%% \item For $k \in \Z, F_k \in \C^{k \times k}$ is the $k \times k$ Fourier matrix with $(F_k)_{ij} = \omega_k^{(i-1)(j-1)}$.
%%   \item For $m, n \in \N, f_m^n = F_m e_n$ is the $n^{\text{th}}$ column of the $m \times m$ unitary Fourier matrix, where $e_n \in \R^m$ has its index taken modulo $m$.
%% \item Given $\x, \y \in \C^d, \x \circ \y$ denotes the Hadamard/elementwise product of $\x$ and $\y$; specifically $(\x \circ \y)_i = \x_i \y_i$.
%% \item Given $A \in \C^{d \times d}, \diag(A, m) \in \C^d$ denotes the $m^{\text{th}}$ circulant off-diagonal of $A$.  That is, $\diag(A, m)_i = A_{i, i + m}$.
%%   \item Given $\x \in \C^d, \diag(\x) \in \C^{d \times d}$ is the diagonal matrix whose diagonal entries are the entries of $\x$.  Namely, $\diag(\x) e_i = \x_i e_i$.  When the intention is clear from context, we may write $D_\x := \diag(\x)$.
%%   \item $\H^d$ is the set of Hermitian matrices in $\C^{d \times d}$, to be viewed as a $d^2$-dimensional vector space over $\R$.
%%     \item $\mathcal{R}_d : \bigcup_{k = 1}^\infty \C^k \to \C^d$ is a universal resize mapping, where for $v \in \C^k,$ \[\mathcal{R}_d(v)_i = \left\{\begin{array}{r@{,\quad}l} v_i & i \le k \\ 0 & \text{otherwise} \end{array}\right. \text{for}\ i \in [d]\]
%% \end{itemize}


\begin{proposition}
  Suppose that $\gamma \in \R^d$ has $1 \in \supp(\gamma) = [\delta].$  Set $D = \min\{2 \delta - 1, d\},$ take $K \ge 2 \delta - 1$ and let \[\begin{array}{r@{\;=\;}r}v_j & \sqrt{K} \mathcal{R}_d(F_K e_j) \\ v_j^D & \sqrt{K} \mathcal{R}_D(F_K e_j) \end{array},\quad j \in [D],\  2 \delta - 1 \le K.\]  Define a local measurement system  $\{m_j\}_{j \in [D]}$ by setting $m_j = \gamma \circ v_j$.  Then $\{m_j\}_{j \in [D]}$ is a spanning family if and only if all the sets $J_k := \{m \in [\delta]_0 : (F_d (\gamma \circ S^{-m} \gamma))_k \neq 0\}$, for all $k \in [d]$ satisfy \[\left\{\begin{array}{r@{,\quad}l} 2 |J_k| - 1 \ge D & 0 \in J_k \\ 2 |J_k| \ge D & \text{otherwise}\end{array}\right..\] \label{prop:span_fam}
\end{proposition}

%% \begin{remark}
%%   We remark that if $D = 2 \delta - 1$, this condition is equivalent to requiring that $J_k = [\delta]$ for each $k$, which means that $F \circop(g_m)$ has no entries equal to zero for any $m \in [\delta]_0$.  Perhaps more intuitively, this stronger condition means that $F (\gamma \circ S^{-m} \gamma)$ has no zeros for any $m \in [\delta]_0$.
%% \end{remark}

The proof will make use of the following lemmas.

\begin{lemma}
  Define $w_j = \mathcal{R}_{N_1}(f_j^{N_2}), j \in [N_2]$ and set \[\rho_j = \mathrm{Re}(w_j) \quad\text{and}\quad \mu_j = \mathrm{Im}(w_j)\] to be vectors containing the real and imaginary components of $w_j$.  Then for $1 \le \ell_1 < \cdots < \ell_k \le \frac{N_2 + 1}{2}$ with $k \le N_1$, we have \begin{align*} \dim\,\Span\{w_{\ell_i}, w_{2 - \ell_i}\}_{i = 1}^k &= \dim\,\Span\{\rho_{\ell_i}, \mu_{\ell_i}\}_{i = 1}^k \\ &= \left\{\begin{array}{r@{,\quad}l} 2k - 1 & \ell_1 = 1 \\ 2k & \text{otherwise}\end{array}\right.,\end{align*} where the indices are taken modulo $N_2$. \label{lem:conjugate_span_dim}
\end{lemma}

\begin{proof}[Proof of lemma \ref{lem:conjugate_span_dim}]

The first equality is clear by considering that $w_{2 - i} = \overline{w_i}$, so $\rho_k = \frac{1}{2}(w_i + w_{2-i})$ and $\mu_i = -\frac{i}{2}(w_i - w_{2 - i})$.  We set $M = \dim\,\Span\{w_{\ell_i}, w_{2 - \ell_i}\}_{i = 1}^k$ to be the common dimension of the two spaces under consideration.

We now divide into two cases: if $N_1 < N_2$, then $\{w_j\}_{j \in [N_2]}$ is full spark, as any $N_1 \times N_1$ submatrix of $\begin{bmatrix} w_1 & \cdots & w_{N_2} \end{bmatrix}$ will be a Vandermonde matrix of the form \[V = \frac{1}{\sqrt{N_2}}\begin{bmatrix} w_{\ell_1} & \cdots & w_{\ell_{N_1}} \end{bmatrix}\] with determinant \[N_2^{-N_1 / 2}\prod_{1 \le i < j \le N_1} (\omega_{N_2}^{\ell_i - 1} - \omega_{N_2}^{\ell_j - 1}),\] which is immediately non-zero since $\omega_{N_2}^{\ell_i - 1} - \omega_{N_2}^{\ell_j - 1} = 0$ only when $\ell_i - \ell_j = 0 \mod N_2$, which cannot happen when $N_1 < N_2$.

When $N_1 \ge N_2, \{w_j\}_{j \in [N_2]}$ is linearly independent, since its members form the matrix $\begin{bmatrix} F_{N_2} \\ 0_{N_1 - N_2 \times N_2} \end{bmatrix}$.

In either case, $M$ is equal to the cardinality of $\{\ell_i, 2 - \ell_i\}_{i = 1}^k,$ which has $2k - 1$ elements if and only if $\ell_1 = 1$; otherwise it has $2k$.  We remark that a collision where $\ell_i = (2 - \ell_i \mod N_2) = N_2 / 2 + 1$ is precluded since we have asserted $\ell_i \le \frac{N_2 + 1}{2}$.

\end{proof}

\begin{lemma}
  For $v \in \R^d,$ we have \begin{align} \circop(v) \rho_k^d &= \frac{1}{2}\mathrm{Re}((Fv)_k f_k^d) \label{eq:real_part} \\ \circop(v) \mu_k^d &= \frac{1}{2}\mathrm{Im}((Fv)_k f_k^d) \label{eq:imag_part}. \end{align} In particular, if $(Fv)_k \neq 0$ and $k \notin \{1, \frac{d}{2} + 1\}$, then $\rho_k^d, \mu_k^d \notin \Nul(\circop(v))$; if $k \in \{1, \frac{d}{2} + 1\}$, then $\rho_k^d \notin \Nul(\circop(v))$ and $\mu_k^d = 0$.  On the other hand, if $(Fv)_k = 0$, then $\rho_k^d, \mu_k^d \in \Nul(\circop(v))$.  \label{lem:eigenbits}
\end{lemma}

\begin{proof}[Proof of lemma \ref{lem:eigenbits}]
  We set $\lambda_k^d = (Fv)_k$, and recalling that $\circop(v) = F \diag(F v) F^*$, we observe that \begin{align*}\circop(v) \mu_k^d &= \circop(v) \frac{1}{2} (f_k^d + f_{2 - k}^d) = \frac{1}{2}(\circop(v) f_k^d + \circop(v) f_{2 - k}^d) \\ &= \frac{1}{2}(\lambda_k^d f_k^d + \lambda_{2 - k}^d f_{2 - k}^d).\end{align*}  \eqref{eq:real_part} follows immediately since $\lambda_k^d = \overline{\lambda_{2 - k}^d}$ when $v \in \R^D$.  \eqref{eq:imag_part} follows from an analogous calculation.

  If $\lambda_k^d \neq 0$ and $k \notin \{1, \frac{d}{2} + 1\}$, then $\omega_d^{k - 1}$ is a non-real root of unity and there exists some $j$ such that $\mathrm{Re}(\omega_d^{(j - 1)(k - 1)} \lambda_k^d) \neq 0,$ and similarly for $\mathrm{Im}(\omega_d^{(j - 1)(k - 1)} \lambda_k^d) \neq 0.$  When $k \in \{1, \frac{d}{2} + 1\}, \omega_d^{(k - 1)} \in \R$ so $\mu_k^d = 0$, but $\lambda_k^d \in \R$ in this case (because $v \in \R^d$), so $\circop(v) \rho_k^d = \lambda_k^d \rho_k^d \neq 0$.  The claim concerning the case of $\lambda_k^d = 0$ is immediate from \eqref{eq:real_part} and \eqref{eq:imag_part}.
\end{proof}

\begin{proof}[Proof of proposition \ref{prop:span_fam}]
  For this proof, we set \begin{align*} (\rho_k^d, \mu_k^d) &= (\mathrm{Re}(f_k^d), \mathrm{Im}(f_k^d)) \\ (\rho_k, \mu_k) &= (\mathrm{Re}(v_k), \mathrm{Im}(v_k)) \\ (\rho_k^D, \mu_k^D) &= (\mathrm{Re}(v_k^D), \mathrm{Im}(v_k^D)) \end{align*}
  
  In this case, we identify $\mathcal{L}_\gamma := \mathcal{L}_{\{m_j\}}$.  By a basic dimension count, $\{m_j\}_{j \in [D]}$ is a spanning family if and only if $\mathcal{L}_\gamma$ is linearly independent, so we consider the conditions under which a linear combination of this lifted measurement system can be equal to zero.  To this end, we define the operator $\mathcal{A}^* : \R^{d \times D} \to \C^{d \times d}$ by \begin{equation} \mathcal{A}^*(C) = \sum_{\ell \in [d], j \in [D]} C_{\ell, j} S^\ell m_j m_j^* S^{-\ell} \label{eq:synth_op} \end{equation} and begin with the observation that, for any $A \in \C^{d \times d}$ we have \[\diag(S^\ell A S^{-\ell}, m) = S^\ell \diag(A, m).\]  We then have
  \[\arraycolsep=1.4pt\def\arraystretch{2}
  \begin{array}{c>{\displaystyle}rcl@{\quad}r}
    & \sum_{j \in [D], \ell \in [d]} C_{\ell, j} S^\ell m_j m_j^* S^{-\ell} & = & 0 & \\
    \iff & \diag\left(\sum_{j \in [D], \ell \in [d]} C_{\ell, j} S^\ell m_j m_j^* S^{-\ell}, m\right) & = & 0 & \text{for all} \ m \in [\delta]_0 \\
    \iff & \sum_{j \in [D], \ell \in [d]} C_{\ell, j} \diag(S^\ell m_j m_j^* S^{-\ell}, m) & = & 0 & \text{for all} \ m \in [\delta]_0 \\
    \iff & \sum_{j \in [D], \ell \in [d]} C_{\ell, j} S^{\ell} \diag(m_j m_j^*, m) & = & 0 & \text{for all} \ m \in [\delta]_0 \\
  \end{array}\]
  
  At this point, we consider that \begin{align} \diag(m_j m_j^*, m) &= \diag((\gamma \circ v_j) (\gamma \circ v_j)^*, m) = \diag(D_{v_j} \gamma \gamma^* D_{\overline{v_j}}, m) \\ &= \omega_K^{m(j - 1)} \diag(\gamma \gamma^*, m). \label{eq:gam_diag}\end{align}  We now set $g_m := \diag(\gamma \gamma^*, m) = \gamma \circ S^{-m} \gamma$ and proceed with the previous chain of implications:
  \[\arraycolsep=1.4pt%\def\arraystretch{1.5}
  \begin{array}{c>{\displaystyle}rcl@{\quad}r}
    & \sum_{j \in [D], \ell \in [d]} C_{\ell, j} S^{\ell} \diag(m_j m_j^*, m) & = & 0 & \text{for all} \ m \in [\delta]_0 \\
    \iff & \sum_{j \in [D], \ell \in [d]} C_{\ell, j} S^{\ell} (\omega_K^{m(j - 1)} g_m) & = & 0 & \text{for all} \ m \in [\delta]_0 \\
    \iff & \sum_{j \in [D], \ell \in [d]} C_{\ell, j} \omega_K^{m(j - 1)} S^{\ell} g_m & = & 0 & \text{for all} \ m \in [\delta]_0 \\
    \iff & \circop(g_m) C \, v^D_{m+1} & = & 0 & \text{for all} \ m \in [\delta]_0 \\
  \end{array}\]

  We now recall that any circulant matrix $\circop(v)$ is diagonalized by the Discrete Fourier Matrix, such that, for $v \in \C^d,$ \begin{equation} \circop(v) = F_d \diag(\sqrt{d} F_d^* v) F_d^* = \sqrt{d} \sum_{j = 1}^d (F_d^* v)_j f_j^d f_j^{d*}. \label{eq:circ_dft_diag} \end{equation}  By writing $\lambda_k^m = \sqrt{d}(F_d^* g_m)_k$, we get a natural decoupling of the previous equations: for a fixed $m$, we have that $\circop(g_m) C v_{m + 1}^D = 0$ if and only if \[\sum_{k = 1}^d \lambda_k^m f_k^d f_k^{d*} C \, v_{m + 1}^D = \sum_{k = 1}^d (\lambda_k^m f_k^{d*} C \, v_{m + 1}^D) f_k^d = 0.\]  Since this last expression is a linear combination of an orthonormal basis, it occurs only when $\lambda_k^m f_k^{d*} C \, v^D_{m + 1} = 0$ for all $k \in [d]$.  We collect these equations over $m \in [\delta]_0$, considering the definition of $J_k$ and that $g_m \in \R^d$ implies $\lambda_k^m = 0 \iff \lambda_{2 - k}^m = 0$ to restate this condition as $\begin{bmatrix} f_k^d & f_{2 - k}^d \end{bmatrix}^* C v^D_{m + 1} = 0$ for all $k \in [d], m \in J_k$.  Since $\Span\{f_k^d, f_{2 - k}^d\} = \Span\{\rho_k^d, \mu_k^d\}$, we further restate this as $\begin{bmatrix} \rho_k^d & \mu_k^d \end{bmatrix}^* C v_{m + 1}^D = 0$ for all $k \in [d], m \in J_k$; setting $W_k = C^* \begin{bmatrix} \rho_k^d & \mu_k^d \end{bmatrix} \in \R^{D \times 2},$ we now get that $\mathcal{A}^*(C) = 0 \iff \Col(W_k) \subset \{v_{m + 1}^D\}_{m \in J_k}^\perp \cap \R^D$ for all $k \in [d]$.

  We now claim that $\mathcal{A}^*$ is invertible if and only if the subspaces $\{v_{m + 1}^D\}_{m \in J_k}^\perp \cap \R^D$ are all trivial.  Indeed, if we fix a $k$ and have some non-zero $u \in \{v_{m + 1}^D\}_{m \in J_k}^\perp \cap \R^D,$ then we may set $C = \rho_k^d u^*$, such that \[\circop(g_m) C v_{m + 1}^D = (\circop(g_m) \rho_k^d) (u^* v_{m + 1}^D).\]  For $m \in J_k, u^* v_{m + 1}^D = 0$ by hypothesis on $u$, and for $m \notin J_k, \circop(g_m) \rho_k^d = 0$ by definition of $J_k$ and lemma \ref{lem:eigenbits}.

  For the other direction, assume $\{v_{m + 1}^D\}_{m \in J_k}^\perp \cap \R^D = 0$ for each $k \in [d]$.  Then $\mathcal{A}^*(C) = 0 \iff \Col(W_k) = \{0\} \iff W_k = 0$ for all $k$.  However, $\{\rho_k^d\}_{k \in [d]} \cup \{\mu_k^d\}_{k \in [d] \setminus \{1, \frac{d}{2} + 1\}}$ is an orthogonal basis for $\R^d$, so \[\begin{array}{cr@{\,=\,}lr} & W_k & 0 & \text{for all} \ k \in [d] \\ \iff & C^* \rho_k^d = C^* \mu_k^d & 0 & \text{for all} \ k \in [d] \\ \iff & C & 0 & \end{array}\]

%  For every $m \in [\delta]_0$ such that $\circop(g_m)$ is non-singular, we must have that $f_{m + 1} \in \Nul(C)$.    Of course, the eigenvalues of $\circop(g_m)$ are given by $F_d g_m = F_d (\gamma \circ S^{-m} \gamma)$, so $\circop(g_m)$ is non-singular exactly when $F_d (\gamma \circ S^{-m})$ has no entries equal to zero (i.e. when $m \in J$).  These conditions then give us that $\Row(C) \subset \{f_{m+1}\}_{m \in J}^\perp \cap \R^{D}$.  Hence $B_\gamma$ is linearly independent if $\{f_{m+1}\}_{m \in J}^\perp \cap \R^{D} = \{0\}$.

  We complete the proof by considering that, for $u \in \R^{D}, \langle v_j^D, u \rangle = 0$ if and only if $\langle \rho_j^D, v \rangle = \langle \mu_j, v \rangle = 0$, so \[\{v_{m + 1}\}_{m \in J_k}^\perp \cap \R^{D} = \{\rho_{m + 1}, \mu_{m + 1}\}_{m \in J_k}^\perp\] which has dimension $\max\{D - (2|J_k| - \one_{0 \in J_k}), 0\}$ by lemma \ref{lem:conjugate_span_dim}.  Therefore, $\mathcal{A}^*$ is invertible if and only if $2|J_k| - \one_{0 \in J_k} \le D$ for all $k \in [d]$, as claimed.
\end{proof}

\begin{remark}
  It turns out that this condition is generic, in the sense that it fails to hold only on a subset of $\R^d$ with Lebesgue measure zero.  We consider that the set of $\gamma \in \R^d$ giving at least one zero in $F(\gamma \circ S^{-m} \gamma)$ is a finite union of zero sets of non-trivial quadratic polynomials (except when $2 \mid d, \delta \ge d / 2,$ and $m = d / 2$, discussed below) and hence a set of zero measure; therefore, $J_k = [\delta]_0$ for all $\gamma$ outside a set of measure zero and $B_\gamma$ is linearly independent under generic conditions.

To address the case of $m = d/2$, we first remark that this is the only possible exception: indeed, when $m \neq d / 2$, we have that \[F((e_1 + e_{m + 1}) \circ S^m(e_1 + e_{m + 1}))_k = f_k^* e_{m + 1} = \omega^{m(k-1)},\] so $\gamma \to F(\gamma \circ S^m \gamma)_k$ is a non-zero, homogeneous quadratic polynomial and therefore has a zero locus of measure zero.

However, when $d = 2m$, then $\gamma \circ S^m \gamma$ is periodic with period $m$ and $F(\gamma \circ S^m \gamma)_{2i} = 0$ for $i \in [m]_0$.  In particular, if $\delta \ge m$, then $D = d$ and $m \notin J_{2i}$ for all $i \in [m]_0$ for any $\gamma$.  In particular, $|J_2| \le \delta - 1$ and $2 |J_2| - \one_{0 \in J_2} \le 2 \delta - 3 $, so if $\delta \in \{d / 2, d/2 + 1\}$,  all choices of $\gamma$ automatically fail to produce a spanning family.

This exception is quite pathological, though: since our intention is to have $\delta \ll d$, this will rarely be an impediment.  Nonetheless, in the case that you \emph{do} want to have $\Span B_\gamma = \H^d$, then taking $\delta > d / 2 + 1$ gives some space for the condition $2|J_k| - \one_{0 \in J_k}$, and we again have that generic $\gamma$ will produce spanning families.
\end{remark}
